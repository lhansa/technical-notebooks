{
  "hash": "228ad307b5d3a932d79aea9f8d795e44",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Estadísticos en regresión lineal por variable\"\ndescription: \"Revisión paso a paso de cómo calcular el p-valor de una variable en una regresión lineal\"\ndescription-meta: \"Guía paso a paso de cómo calcular el p-valor de una variable en una regresión lineal\"\nauthor: \"Leonardo Hansa\"\ndate: \"2024-08-16\"\ncategories: [datos]\nexecute: \n  echo: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n## Intro y datos\nVoy a revisar aquí cómo se calcula el p-valor de una variable en una regresión lineal, porque es una cosa que siempre se me olvida. Y quiero tenerlo a mano.\n\nAdemás, lo voy a hacer en Python porque me gusta sufrir.\n\n::: {#libs .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport statsmodels.api as sm\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nMe invento unos datos que me sirvan para ajustar una regresión lineal: \n\n$$\ny = \\beta_0 + \\beta_1 \\cdot x + \\epsilon,\n$$\n\ndonde $\\beta_0 = - 5$, $\\beta_1 = 3$ y $x ~ \\mbox{Poisson(12)}$ y $\\epislon ~ \\cal{N}(0, 10)$.\n\n::: {#generate-data .cell execution_count=2}\n``` {.python .cell-code}\nnobs = 10000\nx = np.random.poisson(12, nobs)\nnoise = np.random.normal(0, 10, nobs)\n\ny = 3 * x - 5 + noise\n```\n:::\n\n\nAhora ajusto la regresión lineal con **statsmodels**. ¿Se puede hacer con **sklearn**? Pues imagino que sí, pero necesitaré luego acceder a detalles del modelo a los que no sé acceder con sklearn.\n\n::: {#fit-model .cell execution_count=3}\n``` {.python .cell-code}\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.506\nModel:                            OLS   Adj. R-squared:                  0.506\nMethod:                 Least Squares   F-statistic:                 1.026e+04\nDate:                Sat, 17 Aug 2024   Prob (F-statistic):               0.00\nTime:                        16:13:33   Log-Likelihood:                -37249.\nNo. Observations:               10000   AIC:                         7.450e+04\nDf Residuals:                    9998   BIC:                         7.452e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -4.5469      0.362    -12.546      0.000      -5.257      -3.836\nx1             2.9518      0.029    101.282      0.000       2.895       3.009\n==============================================================================\nOmnibus:                        6.863   Durbin-Watson:                   2.032\nProb(Omnibus):                  0.032   Jarque-Bera (JB):                6.843\nSkew:                           0.058   Prob(JB):                       0.0327\nKurtosis:                       3.053   Cond. No.                         45.2\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\nPara calcular el p-valor de $x$ en el modelo necesito el estadístico $t$. Para eso necesito, aparte del valor del coeficiente, el error estándar de la variable. \n\n## Error estándar\n\nEste error estándar relaciona la varianza de la variable con la varianza de los errores: \n\n- Si una variable tiene poca varianza y los errores tienen mucha, la variable está aportando poco al modelo. \n- Si una variable tiene una varianza alta, estará contribuyendo más al modelo. \n- Si un modelo tiene errores con varianza baja, el error estándar de la variable tenderá a ser bajo.\n\n> Cuanto mayor sea el error estándar, menor siginificatividad tendrá la variable. Por lo tanto, con un varianza del error pequeña, más fácil será que la variable aparezca significativa.\n\n::: {#standard-error .cell execution_count=4}\n``` {.python .cell-code}\nstandard_error = np.sqrt(np.sum(model.resid ** 2) / (len(x) - 2))\nstandard_error_x = standard_error / np.sqrt(nobs)  / np.std(x)\n```\n:::\n\n\nEl error estándar de los residuos es 10.034934850057894 y el de la variable es 0.02914455119235981.\n\n> El error estándar del intercept es más lío de calcular e interpretar; la idea intuitiva es que tiene en cuenta la varianza de todas las variables explicativas a la vez. \n\n::: {#cell-standard-error-int .cell execution_count=5}\n``` {.python .cell-code}\nstandard_error * np.sqrt(1 / nobs + np.mean(x) ** 2 / np.sum((x - np.mean(x)) ** 2))\n```\n\n::: {#standard-error-int .cell-output .cell-output-display execution_count=5}\n```\n0.36243203457919937\n```\n:::\n:::\n\n\n## Estadístico $t$\nEl estadístico $t$ se calcula como \n\n$$\nt = \\frac{\\mbox{coef}\\ x}{\\mbox{std error}\\ x}.\n$$ \n\n- Si la variable tiene un error pequeño, el estadístico crece (eso es bueno para la significatividad de la variable). \n- A su vez, si el coeficiente es alto (en valor absoluto), entonces también crece. \n- El estadístico decrece con coeficientes bajos o con errores altos (es decir, la variable parecerá no significativa).\n\n::: {#c84840ce .cell execution_count=6}\n``` {.python .cell-code}\n# label: t-stat\nt_stat_x = np.abs(model.params[1]) / standard_error_x\nt_stat_x\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n101.28170509057901\n```\n:::\n:::\n\n\n## p-valor\nAhora hay que ver qué valor es esperable para el estadístico $t$. \n\nPon que trabajas al nivel de confianza del 90%. Hace falta calcular el $t$ que deja el 5% a un lado de la distribución, y el que lo deja al otro lado. Como la distribución es simétrica, solo calculo uno:\n\n::: {#4a7ebcd4 .cell execution_count=7}\n``` {.python .cell-code}\npercentile = stats.t.ppf(0.95, nobs - 2)\npercentile\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n1.6450060485564049\n```\n:::\n:::\n\n\nAhora tienes la distribución de $t$. Si $t$ cae en el área sombreada (el 10% extremo) entonces la probabilidad de observar tus datos en el supuesto de que la variable no sea significativa ($H_0$ o $\\beta_1 = 0$) es menor de 0,10.\n\n::: {#cell-t-distribution .cell execution_count=8}\n``` {.python .cell-code}\nxx = np.linspace(-4, 4, 1000)\nyy = stats.t.pdf(xx, nobs - 2)\nplt.plot(xx, yy, color='#800080')\n# plot the t distribution and fill the 5% outside \nplt.fill_between(xx, yy, where=(xx < -percentile) | (xx > percentile), alpha=0.5, color='#800080')\nplt.title(f\"Distribución de t con {nobs - 2} grados de libertad\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/t-distribution-output-1.png){#t-distribution width=579 height=432}\n:::\n:::\n\n\nConcretamente, la probabilidad para el estadístico $t$ que has obtenido es muy muy baja.\n\n::: {#1c1b51c6 .cell execution_count=9}\n``` {.python .cell-code}\n# p value for coefficient, extracted from\n# t distribution\nstats.t.sf(t_stat_x, nobs - 2) * 2\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0.0\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}