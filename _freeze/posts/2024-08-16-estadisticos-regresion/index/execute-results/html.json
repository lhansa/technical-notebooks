{
  "hash": "abdec11ba618d5c89fb4c6e88ad330e8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Estadísticos en regresión lineal por variable\"\ndescription: \"Revisión paso a paso de cómo calcular el p-valor de una variable en una regresión lineal\"\ndescription-meta: \"Guía paso a paso de cómo calcular el p-valor de una variable en una regresión lineal\"\nauthor: \"Leonardo Hansa\"\ndate: \"2024-08-16\"\ncategories: [datos]\nexecute: \n  echo: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n## Intro y datos\nVoy a revisar aquí cómo se calcula el p-valor de una variable en una regresión lineal, porque es una cosa que siempre se me olvida. Y quiero tenerlo a mano.\n\nAdemás, lo voy a hacer en Python porque me gusta sufrir.\n\n::: {#libs .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport statsmodels.api as sm\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nMe invento unos datos que me sirvan para ajustar una regresión lineal: \n\n$$\ny = \\beta_0 + \\beta_1 \\cdot x + \\varepsilon,\n$$\n\ndonde $\\beta_0 = - 5$, $\\beta_1 = 3$ y $x ~ \\mbox{Poisson(12)}$ y $\\varepsilon \\sim \\cal{N}(0, 10)$.\n\n::: {#generate-data .cell execution_count=2}\n``` {.python .cell-code}\nnobs = 10000\nx = np.random.poisson(12, nobs)\nnoise = np.random.normal(0, 10, nobs)\n\ny = 3 * x - 5 + noise\n```\n:::\n\n\nAhora ajusto la regresión lineal con **statsmodels**. ¿Se puede hacer con **sklearn**? Pues imagino que sí, pero necesitaré luego acceder a detalles del modelo a los que no sé acceder con sklearn.\n\n::: {#fit-model .cell execution_count=3}\n``` {.python .cell-code}\nX = sm.add_constant(x)\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.520\nModel:                            OLS   Adj. R-squared:                  0.520\nMethod:                 Least Squares   F-statistic:                 1.082e+04\nDate:                Sun, 18 Aug 2024   Prob (F-statistic):               0.00\nTime:                        18:09:08   Log-Likelihood:                -37243.\nNo. Observations:               10000   AIC:                         7.449e+04\nDf Residuals:                    9998   BIC:                         7.450e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -5.0204      0.362    -13.873      0.000      -5.730      -4.311\nx1             3.0175      0.029    104.021      0.000       2.961       3.074\n==============================================================================\nOmnibus:                        0.879   Durbin-Watson:                   1.972\nProb(Omnibus):                  0.644   Jarque-Bera (JB):                0.900\nSkew:                          -0.022   Prob(JB):                        0.638\nKurtosis:                       2.983   Cond. No.                         45.3\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\nPara calcular el p-valor de $x$ en el modelo necesito el estadístico $t$. Para eso necesito, aparte del valor del coeficiente, el error estándar de la variable. \n\n## Error estándar\n\nEste error estándar relaciona la varianza de la variable con la varianza de los errores: \n\n- Si una variable tiene poca varianza y los errores tienen mucha, la variable está aportando poco al modelo. \n- Si una variable tiene una varianza alta, estará contribuyendo más al modelo. \n- Si un modelo tiene errores con varianza baja, el error estándar de la variable tenderá a ser bajo.\n\n> Cuanto mayor sea el error estándar, menor siginificatividad tendrá la variable. Por lo tanto, con un varianza del error pequeña, más fácil será que la variable aparezca significativa.\n\n::: {#standard-error .cell execution_count=4}\n``` {.python .cell-code}\nstandard_error = np.sqrt(np.sum(model.resid ** 2) / (len(x) - 2))\nstandard_error_x = standard_error / np.sqrt(nobs)  / np.std(x)\n```\n:::\n\n\nEl error estándar de los residuos es 10.028521904785437 y el de la variable es 0.029008370883186262.\n\n> El error estándar del intercept es más lío de calcular e interpretar; la idea intuitiva es que tiene en cuenta la varianza de todas las variables explicativas a la vez. \n\n::: {#cell-standard-error-int .cell execution_count=5}\n``` {.python .cell-code}\nstandard_error * np.sqrt(1 / nobs + np.mean(x) ** 2 / np.sum((x - np.mean(x)) ** 2))\n```\n\n::: {#standard-error-int .cell-output .cell-output-display execution_count=5}\n```\n0.3618959071001899\n```\n:::\n:::\n\n\n## Estadístico $t$\nEl estadístico $t$ se calcula como \n\n$$\nt = \\frac{\\mbox{coef}\\ x}{\\mbox{std error}\\ x}.\n$$ \n\n- Si la variable tiene un error pequeño, el estadístico crece (eso es bueno para la significatividad de la variable). \n- A su vez, si el coeficiente es alto (en valor absoluto), entonces también crece. \n- El estadístico decrece con coeficientes bajos o con errores altos (es decir, la variable parecerá no significativa).\n\n::: {#575e98bc .cell execution_count=6}\n``` {.python .cell-code}\n# label: t-stat\nt_stat_x = np.abs(model.params[1]) / standard_error_x\nt_stat_x\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n104.02117567793877\n```\n:::\n:::\n\n\n## p-valor\nAhora hay que ver qué valor es esperable para el estadístico $t$. \n\nPon que trabajas al nivel de confianza del 90%. Hace falta calcular el $t$ que deja el 5% a un lado de la distribución, y el que lo deja al otro lado. Como la distribución es simétrica, solo calculo uno:\n\n::: {#19514061 .cell execution_count=7}\n``` {.python .cell-code}\npercentile = stats.t.ppf(0.95, nobs - 2)\npercentile\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n1.6450060485564049\n```\n:::\n:::\n\n\nAhora tienes la distribución de $t$. Si $t$ cae en el área sombreada (el 10% extremo) entonces la probabilidad de observar tus datos en el supuesto de que la variable no sea significativa ($H_0$ o $\\beta_1 = 0$) es menor de 0,10.\n\n::: {#cell-t-distribution .cell execution_count=8}\n``` {.python .cell-code}\nxx = np.linspace(-4, 4, 1000)\nyy = stats.t.pdf(xx, nobs - 2)\nplt.plot(xx, yy, color='#800080')\n# plot the t distribution and fill the 5% outside \nplt.fill_between(xx, yy, where=(xx < -percentile) | (xx > percentile), alpha=0.5, color='#800080')\nplt.title(\"Distribución de t\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/t-distribution-output-1.png){#t-distribution width=579 height=431}\n:::\n:::\n\n\nConcretamente, la probabilidad para el estadístico $t$ que has obtenido es muy muy baja.\n\n::: {#b6a15302 .cell execution_count=9}\n``` {.python .cell-code}\n# p value for coefficient, extracted from\n# t distribution\nstats.t.sf(t_stat_x, nobs - 2) * 2\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0.0\n```\n:::\n:::\n\n\n## Idea intuitiva\n\nLo que estás haciendo con esto es calcular la probabilidad de obtener los datos que tienes si asumes que las dos variables no tienen relación. \n\nImagina que estás midiendo la relación entre el consumo de torreznos (gramos de torreznos semanales) y los niveles de colesterol (ni idea de qué unidad se usa en los análisis). \n\nLa forma de pensar con este análisis sería: \n\n- Asumes que no hay relación\n- Tienes unos datos de varias personas, con su consumo de torreznos y el nivel de colesterol. \n- Haces el cálculo de la regresión. \n- El p-valor es cómo de probables son tus datos. \n- Si tu p-valor es pequeño, entonces los datos son poco probables en el supuesto de que no haya relación. Así que deduces que sí hay relación. \n\n**¿Qué quiero decir con que tu p-valor sea pequeño?**\n\nMe refiero a que, previamente, habrás definido un umbral. Que tu p-valor sea pequeño significa que está por debajo de ese umbral. \n\n¿Cuál debería ser tu umbral? Normalmente es 0,05. Eso se traduce en que: \n\n- Si la probabilidad de observar tus datos en el supuesto de que no hay relación (p-valor) es menor de 0,05, entonces es que sí hay relación. \n- Si la probabilidad (p-valor) es mayor, entonces es que no hay relación. \n\nY te pregunto yo. ¿Cuál debería ser para ti la probabilidad? Por ejemplo, si el p-valor es 0,20, ¿automáticamente concluyes que no hay relación?\n\n¿Por qué?\n\nSi tu p-valor es ese, estarías diciendo que la probabilidad de observar tus datos cuando no hubiera relación real es de un 20%. Quizá en un caso médico tienes que tener cuidado, como con lo del colesterol. ¿Pero qué pasa si estás midiendo la eficacia de una acción empresarial?\n\n## Un ejemplo más extremo\n\n::: {#cell-genera-escenario .cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/genera-escenario-output-1.png){#genera-escenario width=579 height=431}\n:::\n:::\n\n\n::: {#cell-prueba-variables .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/prueba-variables-output-1.png){#prueba-variables width=575 height=431}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}