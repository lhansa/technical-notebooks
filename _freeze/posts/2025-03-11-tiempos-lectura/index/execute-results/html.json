{
  "hash": "b5b2821a3321182b56e64601e6a26c3a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tiempos de lectura de un fichero Excel\"\ndescription: \"Ejercicio de exploración de tiempos de lectura de un fichero Excel\"\ndescription-meta: \"Ejercicio de exploración de tiempos de lectura de un fichero Excel\"\nauthor: \"Leonardo Hansa\"\ndate: \"2025-03-11\"\ncategories: [exploraciones]\nexecute: \n  echo: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n\nVoy a intentar mejorar el tiempo de lectura de un fichero Excel. \n\n## Preparación de datos\n\nNo tengo ninguno a mano, así que me lo invento. Genero un data frame con 1000 filas y 100 columnas y lo guardo en un fichero Excel.\n\nLas columnas serán de distintos tipos: \n\n- Las 10 primeras columnas serán de tipo fecha. \n- Las 10 columnas siguientes serán de tipo entero.\n- Las 10 columnas siguienets serán de tipo character. \n- Las demás columnas serán de tipo numérico.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\nn <- 10000\nm <- 100\n\ndf_fechas <- data.frame(\n  lapply(1:10, function(i) {\n    as.Date(\"2025-01-01\") + sample(1:1000, n, replace = TRUE)\n  })\n)\n\nnames(df_fechas) <- paste0(\"fecha_\", 1:10)\n\ndf_enteros <- data.frame(\n  lapply(1:10, function(i) {\n    sample(1:1000, n, replace = TRUE)\n  })\n)\n\nnames(df_enteros) <- paste0(\"entero_\", 1:10)\n\ndf_caracter <- data.frame(\n  lapply(1:10, function(i) {\n    sample(letters, n, replace = TRUE)\n  })\n)\n\nnames(df_caracter) <- paste0(\"caracter_\", 1:10)\n\ndf_numericos <- data.frame(\n  lapply(1:(m - 30), function(i) {\n    rnorm(n)\n  })\n)\n\nnames(df_numericos) <- paste0(\"numerico_\", 1:(m - 30))\n\ndf <- cbind(df_fechas, df_enteros, df_caracter, df_numericos)\n\nwritexl::write_xlsx(df, \"~/Desktop/datos.xlsx\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## Prueba 1\n\nAhora leo el fichero Excel con la función `readxl::read_xlsx` y cuento tiempos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\nlibrary(readxl)\n\nmicrobenchmark(\n  excel = readxl::read_excel(\"~/Desktop/datos.xlsx\"),\n  xlsx = readxl::read_xlsx(\"~/Desktop/datos.xlsx\"),\n  times = 10\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n  expr      min       lq     mean   median       uq       max neval\n excel 818.9073 822.9448 859.8217 831.0066 932.1684  945.2294    10\n  xlsx 815.5541 844.9630 941.4324 855.8534 938.4878 1501.5206    10\n```\n\n\n:::\n:::\n\n\n\nFlipo por primera vez porque dejar que averigüe la extensión es más rápido que especificársela.\n\n## Prueba 2\n\nAhora intento acelerar esto. Una opción es usar la función `readxl::read_xlsx` con el argumento `guess_max`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicrobenchmark(\n  xlsx_1000 = readxl::read_xlsx(\"~/Desktop/datos.xlsx\"),\n  xlsx_10 = readxl::read_xlsx(\"~/Desktop/datos.xlsx\", guess_max = 10),\n  times = 10\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n      expr      min       lq     mean   median       uq       max neval\n xlsx_1000 810.2359 828.9868 891.8215 887.9481 942.6632 1013.5234    10\n   xlsx_10 819.4436 830.5079 872.8056 848.1881 908.9467  987.3453    10\n```\n\n\n:::\n:::\n\n\n\nFlipo por segunda vez porque dejar que adivine con 10 filas es más lento que dejarle que adivine con 1000.\n\n## Prueba 3\n\nAhora voy a especificar los tipos de columnas en el argumento col_types. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol_types <- c(\n  rep(\"date\", 10),\n  rep(\"numeric\", 10),\n  rep(\"text\", 10),\n  rep(\"numeric\", m - 30)\n)\n\nmicrobenchmark(\n  xlsx_1000 = readxl::read_xlsx(\"~/Desktop/datos.xlsx\"),\n  xlsx_col_types = readxl::read_xlsx(\"~/Desktop/datos.xlsx\", col_types = col_types),\n  times = 10\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: milliseconds\n           expr      min       lq     mean   median       uq      max neval\n      xlsx_1000 819.3382 826.5695 860.4852 834.8801 854.2142 989.9864    10\n xlsx_col_types 818.9725 829.1812 855.8303 846.0230 854.6138 923.9795    10\n```\n\n\n:::\n:::\n\n\n\n\nY me quedo flipando aún más porque lo de especificar `col_types` apenas ayuda (de hecho, si el número de filas es 1000 en lugar de 10000, empeora el tiempo; por lo menos, en una prueba que he hecho pero no he publicado).\n\n***\n\nMira, esto tiene trampa. El fichero Excel con el que estoy probando es pequeño. Si pruebas con un fichero grande, tipo 500.000 filas, o 1.000.000, es posible que los resultados sean más razonables. \n\nYo no lo hago porque mi ordenador peta. Pero lo puedes probar tú. Seguramente sí consigas en ese caso mejoras según dicta la intuición. Ahora bien, no creo que sean mejoras enormes. \n\nSon mejoras que, si tienes que leer el fichero una vez, te van a dar igual. Te pueden venir bien si tienes muchos ficheros que leer, de forma que te ahorres 1 segundo por fichero y, en suma, aporte. \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}