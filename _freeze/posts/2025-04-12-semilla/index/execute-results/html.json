{
  "hash": "988c141d29c38a374ef226eedecf4b14",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Cuánto te afecta la semilla al resultado final\"\ndescription: \"La semilla afecta a la aleatoriedad del ajuste del modelo. Esto puede generar una incertidumbre que no siempre se tiene en cuenta.\"\ndescription-meta: \"La semilla afecta a la aleatoriedad del ajuste del modelo. Esto puede generar una incertidumbre que no siempre se tiene en cuenta.\"\nauthor: \"Leonardo Hansa\"\ndate: \"2025-04-12\"\ncategories: [exploraciones]\nexecute: \n  echo: true\n  eval: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n## Comentarios iniciales\n\nEn [Cuartil](https://open.spotify.com/episode/0Bl4iZq1o5s2Kd5WESm2Cu?si=LgiczmLkTfOpc0vKREYI9w) mencionamos que cambiar la semilla puede cambiar la métrica de ajuste de tu modelo.\n\nVoy a ajustar un RandomForest en algún conjunto de datos varias veces. \n\nEl objetivo es ver que, cada vez que lo ejecuto, la predicción cambia, por lo que hay cierta incertidumbre cada vez que ajustas un modelo de estos. \n\n::: {#libs .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n## Preparación de datos\n\nLos datos no me importan especialmente. Cargo unos de **sklearn** que me ha sugerido ChatGPT. Los separo en train y test. Esta separación la dejo fija: voy a estudiar cómo afecta la aleatoriedad del modelo, no la de los datos.\n\n::: {#data .cell execution_count=2}\n``` {.python .cell-code}\ndata = load_diabetes()\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n```\n:::\n\n\n## Ajuste de los modelos\n\nAjusto 100 modelos. Voy a guardar algunas cosas de los ajustes para luego ver cómo varían de un caso a otro. Lo que quiero estudiar es si hay mucha dispersión entre unos resultados y otros.\n\n::: {#loop-model .cell execution_count=3}\n``` {.python .cell-code}\nnum_trials = 200\nl_r2 = []\nl_preds = []\n\nfor i in range(num_trials):\n    random_state = np.random.randint(0, 10000)\n\n    model = RandomForestRegressor(random_state=random_state, n_jobs=-1)\n\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    l_r2.append(r2_score(y_test, y_pred))\n\n    pred_series = pd.Series(y_pred, name=f\"pred_{i}\")\n\n    l_preds.append(pred_series)\n```\n:::\n\n\nAhora creo el data frame de predicciones:\n\n::: {#concat .cell execution_count=4}\n``` {.python .cell-code}\ndf_preds = pd.concat(l_preds, axis=1)\n```\n:::\n\n\n## Visualización\n\n### Métrica de ajuste\n\nAquí la distribución del R2.\n\n::: {#cell-hist-mse .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/hist-mse-output-1.png){#hist-mse width=758 height=470}\n:::\n:::\n\n\n### Predicciones\n\nAhora muestro cómo varía cada predicción observación a observación. Muestro solo unas pocas porque no se ve nada si intento ver todas una a una. \n\nQuizá no tenga sentido ver todas una a una, sino ver la desviación en general de todas las observación con respecto a su punto medio o su media o lo que sea. Pero paso de pensar. \n\n::: {#cell-preds-boxplots .cell execution_count=6}\n``` {.python .cell-code}\ndf_long = df_preds.reset_index().melt(\n    id_vars=\"index\", var_name=\"modelo\", value_name=\"pred\"\n)\ndf_long = df_long.rename(columns={\"index\": \"id\"})\n\nsubset_ids = df_long[\"id\"].unique()[:50]\nsubset = df_long[df_long[\"id\"].isin(subset_ids)]\n\n# Calcular mediana por id\nmedianas = subset.groupby(\"id\")[\"pred\"].median().sort_values()\n\n# Convertir 'id' a categoría ordenada según su mediana\nsubset[\"id\"] = pd.Categorical(subset[\"id\"], categories=medianas.index, ordered=True)\n\nplt.figure(figsize=(20, 6))\nsns.boxplot(data=subset, x=\"id\", y=\"pred\", showfliers=False)\nplt.xlabel(\"ID de observación (subconjunto)\")\nplt.ylabel(\"Predicción\")\nplt.title(\"Boxplot de predicciones por observación (unas pocas)\")\nplt.xticks(rotation=90, fontsize=5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/preds-boxplots-output-1.png){#preds-boxplots width=1910 height=568}\n:::\n:::\n\n\nHay alguna observación que sí presenta algo de variabilidad entre los modelos pero no me escandizaría por ello. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}