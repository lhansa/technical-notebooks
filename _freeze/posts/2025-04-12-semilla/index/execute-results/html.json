{
  "hash": "cb2a2f4ee63b2fe55f3f69c4a3b27a02",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Cuánto te afecta la semilla al resultado final\"\ndescription: \"La semilla afecta a la aleatoriedad del ajuste del modelo. Esto puede generar una incertidumbre que no siempre se tiene en cuenta.\"\ndescription-meta: \"La semilla afecta a la aleatoriedad del ajuste del modelo. Esto puede generar una incertidumbre que no siempre se tiene en cuenta.\"\nauthor: \"Leonardo Hansa\"\ndate: \"2025-04-12\"\ncategories: [exploraciones]\nexecute: \n  echo: true\n  eval: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n## Comentarios iniciales\n\nEn [Cuartil](https://open.spotify.com/episode/0Bl4iZq1o5s2Kd5WESm2Cu?si=LgiczmLkTfOpc0vKREYI9w) mencionamos que cambiar la semilla puede cambiar la métrica de ajuste de tu modelo.\n\nVoy a ajustar un RandomForest en algún conjunto de datos varias veces. \n\nEl objetivo es ver que, cada vez que lo ejecuto, la predicción cambia, por lo que hay cierta incertidumbre cada vez que ajustas un modelo de estos. \n\n::: {#libs .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import fetch_california_housing, load_breast_cancer\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n## Ejemplo 1. Regresión\n\n### Preparación de datos\n\nLos datos no me importan especialmente. Cargo unos de **sklearn** que me ha sugerido ChatGPT. Los separo en train y test. Esta separación la dejo fija: voy a estudiar cómo afecta la aleatoriedad del modelo, no la de los datos.\n\n::: {#data .cell execution_count=2}\n``` {.python .cell-code}\ndata = fetch_california_housing(as_frame=True)\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\n### Ajuste de los modelos\n\nAjusto 100 modelos. Voy a guardar algunas cosas de los ajustes para luego ver cómo varían de un caso a otro. Lo que quiero estudiar es si hay mucha dispersión entre unos resultados y otros.\n\n::: {#loop-model .cell execution_count=3}\n``` {.python .cell-code}\nnum_trials = 100\nl_mse = []\ndf_preds = pd.DataFrame()\n\nfor i in range(num_trials):\n  print(f'Iteración {i+1}/{num_trials}')\n  random_state = np.random.randint(0, 10000)\n\n  model = RandomForestRegressor(\n    random_state=random_state, \n    n_jobs=-1\n  )\n\n  model.fit(X_train, y_train)\n\n  y_pred = model.predict(X_test)\n  l_mse.append(mean_squared_error(y_test, y_pred))\n\n  df_preds[f'pred_{i}'] = y_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIteración 1/100\nIteración 2/100\nIteración 3/100\nIteración 4/100\nIteración 5/100\nIteración 6/100\nIteración 7/100\nIteración 8/100\nIteración 9/100\nIteración 10/100\nIteración 11/100\nIteración 12/100\nIteración 13/100\nIteración 14/100\nIteración 15/100\nIteración 16/100\nIteración 17/100\nIteración 18/100\nIteración 19/100\nIteración 20/100\nIteración 21/100\nIteración 22/100\nIteración 23/100\nIteración 24/100\nIteración 25/100\nIteración 26/100\nIteración 27/100\nIteración 28/100\nIteración 29/100\nIteración 30/100\nIteración 31/100\nIteración 32/100\nIteración 33/100\nIteración 34/100\nIteración 35/100\nIteración 36/100\nIteración 37/100\nIteración 38/100\nIteración 39/100\nIteración 40/100\nIteración 41/100\nIteración 42/100\nIteración 43/100\nIteración 44/100\nIteración 45/100\nIteración 46/100\nIteración 47/100\nIteración 48/100\nIteración 49/100\nIteración 50/100\nIteración 51/100\nIteración 52/100\nIteración 53/100\nIteración 54/100\nIteración 55/100\nIteración 56/100\nIteración 57/100\nIteración 58/100\nIteración 59/100\nIteración 60/100\nIteración 61/100\nIteración 62/100\nIteración 63/100\nIteración 64/100\nIteración 65/100\nIteración 66/100\nIteración 67/100\nIteración 68/100\nIteración 69/100\nIteración 70/100\nIteración 71/100\nIteración 72/100\nIteración 73/100\nIteración 74/100\nIteración 75/100\nIteración 76/100\nIteración 77/100\nIteración 78/100\nIteración 79/100\nIteración 80/100\nIteración 81/100\nIteración 82/100\nIteración 83/100\nIteración 84/100\nIteración 85/100\nIteración 86/100\nIteración 87/100\nIteración 88/100\nIteración 89/100\nIteración 90/100\nIteración 91/100\nIteración 92/100\nIteración 93/100\nIteración 94/100\nIteración 95/100\nIteración 96/100\nIteración 97/100\nIteración 98/100\nIteración 99/100\nIteración 100/100\n```\n:::\n:::\n\n\n### Visualización\n\n#### Métrica de ajuste\n\nReconozco que esperaba más dispersión entre las métricas. Entre los 100 modelos, la métrica de ajuste (MSE) varía entre 0.25 y 0.26. Muy estable.\n\n::: {#cell-hist-mse .cell execution_count=4}\n``` {.python .cell-code}\nplt.hist(l_mse, bins=20)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/hist-mse-output-1.png){#hist-mse width=566 height=411}\n:::\n:::\n\n\n### Predicciones\n\nAhora muestro cómo varía cada predicción observación a observación. Muestro solo unas pocas porque no se ve nada si intento ver todas una a una. \n\nQuizá no tenga sentido ver todas una a una, sino ver la desviación en general de todas las observación con respecto a su punto medio o su media o lo que sea. Pero paso de pensar. \n\n::: {#cell-preds-boxplots .cell execution_count=5}\n``` {.python .cell-code}\ndf_long = df_preds.reset_index().melt(id_vars='index', var_name='modelo', value_name='pred')\ndf_long = df_long.rename(columns={'index': 'id'})\n\nsubset_ids = df_long['id'].unique()[:50]\nsubset = df_long[df_long['id'].isin(subset_ids)]\n\nplt.figure(figsize=(20, 6))\nsns.boxplot(data=subset, x='id', y='pred', showfliers=False)\nplt.xlabel('ID de observación (subconjunto)')\nplt.ylabel('Predicción')\nplt.title('Boxplot de predicciones por observación (100 primeras)')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/preds-boxplots-output-1.png){#preds-boxplots width=1910 height=567}\n:::\n:::\n\n\nHay alguna observación que sí presenta algo de variabilidad entre los modelos pero no me escandizaría por ello. \n\n## Ejemplo 2. Clasificación\n\nAhora quiero hacer algo parecido en un problema de clasificación 0-1. \n\n### Preparación de datos\n\n::: {#data-class .cell execution_count=6}\n``` {.python .cell-code}\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\n### Ajuste de modelos\n\n::: {#modelos .cell execution_count=7}\n``` {.python .cell-code}\nall_preds = []\nall_aucs = []\n\nfor i in range(100):  # 100 semillas\n    model = RandomForestClassifier(random_state=i, n_jobs=-1)\n    model.fit(X_train, y_train)\n    probs = model.predict_proba(X_test)[:, 1]\n    \n    # Guardar predicciones\n    df_temp = pd.DataFrame({\n        'id': range(len(X_test)),\n        'prob': probs,\n        'seed': i,\n        'true_label': y_test\n    })\n    all_preds.append(df_temp)\n    \n    # Calcular y guardar AUC\n    auc = roc_auc_score(y_test, probs)\n    all_aucs.append(auc)\n```\n:::\n\n\n### Visualización\n\n#### Bondad de ajuste\n\n::: {#cell-hist-auc .cell execution_count=8}\n``` {.python .cell-code}\ndf_all = pd.concat(all_preds, ignore_index=True)\n\nplt.figure(figsize=(8, 4))\nsns.histplot(all_aucs, bins=20, kde=True)\nplt.xlabel('AUC')\nplt.title('Distribución de AUCs sobre 100 random forests')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/hist-auc-output-1.png){#hist-auc width=758 height=374}\n:::\n:::\n\n\n#### Probabalidad por observación\n\n::: {#daaaf002 .cell execution_count=9}\n``` {.python .cell-code}\n# Unir todos los resultados\ndf_all = pd.concat(all_preds, ignore_index=True)\n\n# Crear gráfico\nplt.figure(figsize=(10, 8))\nsns.stripplot(data=df_all, x='prob', y='id', hue='true_label', dodge=True, alpha=0.6, palette='Set1', jitter=0)\nplt.axvline(x=50, color='gray', linestyle='--')\nplt.xlabel('Probabilidad predicha (clase 1)')\nplt.ylabel('ID de observación')\nplt.xticks(ticks=range(0, len(df_all['id'].unique()), len(df_all['id'].unique()) // 5))\nplt.title('Variabilidad de predicciones por semilla (Random Forest)')\nplt.legend(title='Clase real', loc='lower right')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=950 height=758}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}