{
  "hash": "4c38fa09deca22c9283c80efa3d099da",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Cómo corregir el optimismo de tu modelo estadístico\"\ndescription: \"Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos.\"\ndescription-meta: \"Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos.\"\nauthor: \"Leonardo Hansa\"\ndate: \"2025-04-17\"\ncategories: [exploraciones]\nexecute: \n  echo: true\n  eval: true\n  message: false\n  warning: false\nfreeze: true\n---\n\n\n## Comentarios iniciales\n\nSi entrenas un modelo en un conjunto de datos que no es muy grande, la métrica de ajuste que reportes no deberías calcularla sobre los datos de entrenamiento. Esto es porque el modelo ya conoce esos datos y se ha entrenado con ellos, intentando optimizar esa métrica de ajuste. \n\nLo típico es reservar un conjunto de validación, unos datos que el modelo no conoce, por lo que la métrica de ajuste no tendrá ese sesgo. \n\nA ese sesgo lo llamamos _optimismo._\n\nLo malo, según Frank Harrell, es que, si tu conjunto de datos es pequeño, esa validación no será suficiente estable.\n\n_Bootstrap_ es una solución. \n\n::: {#libs .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.utils import resample\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Bootstrap para corregir el optimismo\n\nLa idea es entrenar el modelo en varias muestras bootstrap y calcular la métrica de ajuste en cada par muestra bootstrap, muestra original, y luego la diferencia. Así, tendrás una lista de diferencias de longitud el número de muestras. \n\nLuego calculas la media. \n\nFinalmente, entrenas el modelo en la muestra original completa y le aplicas esa diferencia media. \n\nLa métrica de ajuste final será la métrica de ajuste en entrenamiento menos la diferencia, es decir, con el optimismo corregido.\n\n### Algunos datos\n\n::: {#load .cell execution_count=2}\n``` {.python .cell-code}\ndata = fetch_openml(name=\"boston\", version=1, as_frame=True)\nX = data.data\ny = data.target\n\nX_np = X.to_numpy()\ny_np = y.to_numpy()\n```\n:::\n\n\n### Entrenamiento en muestras bootstrap\n\n::: {#set-up-boots .cell execution_count=3}\n``` {.python .cell-code}\nn_bootstraps = 200\n```\n:::\n\n\nLo siguiente creo que quedaría más claro con un bucle `for`, pero en teoría no están recomendados. Así que creo una función y la llamo en una _list comprehension_. \n\n::: {#compute-optimism .cell execution_count=4}\n``` {.python .cell-code}\ndef compute_optimism():\n    X_boot, y_boot = resample(X_np, y_np)\n\n    model = LinearRegression()\n    model.fit(X_boot, y_boot)\n\n    y_pred_boot = model.predict(X_boot)\n    r2_boot = r2_score(y_boot, y_pred_boot)\n\n    y_pred_orig = model.predict(X_np)\n    r2_orig = r2_score(y_np, y_pred_orig)\n\n    return(r2_boot - r2_orig)\n```\n:::\n\n\nY ahora calculo todo.\n\n::: {#list-optimism .cell execution_count=5}\n``` {.python .cell-code}\noptimism_estimates = [compute_optimism() for _ in range(n_bootstraps)]\n```\n:::\n\n\n### Cálculo del optimismo\n\nEl optimismo medio es lo que necesito para el próximo paso. Así que calculo la media de la lista que acabo de generar.\n\n::: {#cell-optimism .cell execution_count=6}\n``` {.python .cell-code}\nmean_optimism = np.mean(optimism_estimates)\nmean_optimism\n```\n\n::: {#optimism .cell-output .cell-output-display execution_count=6}\n```\n0.019051516450253544\n```\n:::\n:::\n\n\nPor curiosidad, así se distribuye el optimismo.\n\n::: {#cell-histogram .cell execution_count=7}\n``` {.python .cell-code}\nplt.figure(figsize=(8, 5))\nplt.hist(optimism_estimates, bins=20, color=\"#800080\", edgecolor=\"black\", alpha=0.75)\n\nplt.title(\n    \"Distribución del optimismo del modelo (bootstrap)\", fontsize=14, fontweight=\"bold\"\n)\nplt.xlabel(\"Optimismo estimado\", fontsize=12)\nplt.ylabel(\"Frecuencia\", fontsize=12)\n\nplt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.3)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/histogram-output-1.png){#histogram width=759 height=470}\n:::\n:::\n\n\n### Entrenamiento final\n\nTodos los entrenamientos anteriores estaban hechos sobre muestras _bootrstrap_, es decir, no estaban sobre el entrenamiento\n\n::: {#final-train .cell execution_count=8}\n``` {.python .cell-code}\nfinal_model = LinearRegression()\nfinal_model.fit(X_np, y_np)\nfinal_r2 = r2_score(y_np, final_model.predict(X_np))\n```\n:::\n\n\n::: {#optimism-correct .cell execution_count=9}\n``` {.python .cell-code}\ncorrected_r2 = final_r2 - mean_optimism\n\nprint(f\"R² original: {final_r2:.4f}\")\nprint(f\"Optimismo medio: {mean_optimism:.4f}\")\nprint(f\"R² corregido: {corrected_r2:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR² original: 0.7406\nOptimismo medio: 0.0191\nR² corregido: 0.7216\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}