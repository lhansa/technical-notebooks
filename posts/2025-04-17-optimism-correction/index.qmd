---
title: "Cómo corregir el optimismo de tu modelo estadístico"
description: "Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos."
description-meta: "Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos."
author: "Leonardo Hansa"
date: "2025-04-17"
categories: [exploraciones]
execute: 
  echo: true
  eval: true
  message: false
  warning: false
freeze: true
---

## Comentarios iniciales

Si entrenas un modelo en un conjunto de datos que no es muy grande, la métrica de ajuste que reportes no deberías calcularla sobre los datos de entrenamiento. Esto es porque el modelo ya conoce esos datos y se ha entrenado con ellos, intentando optimizar esa métrica de ajuste. 

Lo típico es reservar un conjunto de validación, unos datos que el modelo no conoce, por lo que la métrica de ajuste no tendrá ese sesgo. 

A ese sesgo lo llamamos _optimismo._

Lo malo, según Frank Harrell, es que, si tu conjunto de datos es pequeño, esa validación no será suficiente estable.

_Bootstrap_ es una solución. 

## Bootstrap para corregir el optimismo


```{python}
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.utils import resample

# Cargar los datos
data = fetch_openml(name="boston", version=1, as_frame=True)
X = data.data
y = data.target

# Convertir a numpy
X_np = X.to_numpy()
y_np = y.to_numpy()

# Definir el número de muestras bootstrap
n_bootstraps = 200
optimism_estimates = []

# Bucle bootstrap
for _ in range(n_bootstraps):
    # Muestra bootstrap (con reemplazo)
    X_boot, y_boot = resample(X_np, y_np)

    # Entrenar el modelo en el bootstrap
    model = LinearRegression()
    model.fit(X_boot, y_boot)

    # Evaluar en el bootstrap (optimista)
    y_pred_boot = model.predict(X_boot)
    r2_boot = r2_score(y_boot, y_pred_boot)

    # Evaluar en los datos originales (menos optimista)
    y_pred_orig = model.predict(X_np)
    r2_orig = r2_score(y_np, y_pred_orig)

    # Guardar diferencia
    optimism = r2_boot - r2_orig
    optimism_estimates.append(optimism)

# Estimar el optimismo medio
mean_optimism = np.mean(optimism_estimates)

# Entrenar modelo final en todos los datos
final_model = LinearRegression()
final_model.fit(X_np, y_np)
final_r2 = r2_score(y_np, final_model.predict(X_np))

# Corregir el R² final
corrected_r2 = final_r2 - mean_optimism

# Mostrar resultados
print(f"R² original: {final_r2:.4f}")
print(f"Optimismo medio: {mean_optimism:.4f}")
print(f"R² corregido: {corrected_r2:.4f}")

```