{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Cómo corregir el optimismo de tu modelo estadístico\"\n",
        "description: \"Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos.\"\n",
        "description-meta: \"Bootstrap aplicado a la corrección del optimismo de un modelo estadístico cuando tienes pocos datos.\"\n",
        "author: \"Leonardo Hansa\"\n",
        "date: \"2025-04-17\"\n",
        "categories: [exploraciones]\n",
        "execute: \n",
        "  echo: true\n",
        "  eval: true\n",
        "  message: false\n",
        "  warning: false\n",
        "freeze: true\n",
        "---\n",
        "\n",
        "\n",
        "## Comentarios iniciales\n",
        "\n",
        "Si entrenas un modelo en un conjunto de datos que no es muy grande, la métrica de ajuste que reportes no deberías calcularla sobre los datos de entrenamiento. Esto es porque el modelo ya conoce esos datos y se ha entrenado con ellos, intentando optimizar esa métrica de ajuste. \n",
        "\n",
        "Lo típico es reservar un conjunto de validación, unos datos que el modelo no conoce, por lo que la métrica de ajuste no tendrá ese sesgo. \n",
        "\n",
        "A ese sesgo lo llamamos _optimismo._\n",
        "\n",
        "Lo malo, según Frank Harrell, es que, si tu conjunto de datos es pequeño, esa validación no será suficiente estable.\n",
        "\n",
        "_Bootstrap_ es una solución. \n"
      ],
      "id": "0532dbe2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: libs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "libs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bootstrap para corregir el optimismo\n",
        "\n",
        "La idea es entrenar el modelo en varias muestras bootstrap y calcular la métrica de ajuste en cada par muestra bootstrap, muestra original, y luego la diferencia. Así, tendrás una lista de diferencias de longitud el número de muestras. \n",
        "\n",
        "Luego calculas la media. \n",
        "\n",
        "Finalmente, entrenas el modelo en la muestra original completa y le aplicas esa diferencia media. \n",
        "\n",
        "La métrica de ajuste final será la métrica de ajuste en entrenamiento menos la diferencia, es decir, con el optimismo corregido.\n",
        "\n",
        "### Algunos datos\n"
      ],
      "id": "3635b999"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load\n",
        "data = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_np = X.to_numpy()\n",
        "y_np = y.to_numpy()"
      ],
      "id": "load",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento en muestras bootstrap\n"
      ],
      "id": "58a527d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: set-up-boots\n",
        "n_bootstraps = 200"
      ],
      "id": "set-up-boots",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo siguiente creo que quedaría más claro con un bucle `for`, pero en teoría no están recomendados. Así que creo una función y la llamo en una _list comprehension_. \n"
      ],
      "id": "0a96a281"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: compute-optimism\n",
        "def compute_optimism():\n",
        "    X_boot, y_boot = resample(X_np, y_np)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_boot, y_boot)\n",
        "\n",
        "    y_pred_boot = model.predict(X_boot)\n",
        "    r2_boot = r2_score(y_boot, y_pred_boot)\n",
        "\n",
        "    y_pred_orig = model.predict(X_np)\n",
        "    r2_orig = r2_score(y_np, y_pred_orig)\n",
        "\n",
        "    return(r2_boot - r2_orig)"
      ],
      "id": "compute-optimism",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y ahora calculo todo.\n"
      ],
      "id": "584db488"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: list-optimism\n",
        "optimism_estimates = [compute_optimism() for _ in range(n_bootstraps)]"
      ],
      "id": "list-optimism",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cálculo del optimismo\n",
        "\n",
        "El optimismo medio es lo que necesito para el próximo paso. Así que calculo la media de la lista que acabo de generar.\n"
      ],
      "id": "ec39705c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: optimism\n",
        "mean_optimism = np.mean(optimism_estimates)\n",
        "mean_optimism"
      ],
      "id": "optimism",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por curiosidad, así se distribuye el optimismo.\n"
      ],
      "id": "943115b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(optimism_estimates, bins=20, color=\"#800080\", edgecolor=\"black\", alpha=0.75)\n",
        "\n",
        "plt.title(\n",
        "    \"Distribución del optimismo del modelo (bootstrap)\", fontsize=14, fontweight=\"bold\"\n",
        ")\n",
        "plt.xlabel(\"Optimismo estimado\", fontsize=12)\n",
        "plt.ylabel(\"Frecuencia\", fontsize=12)\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.3)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "histogram",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento final\n",
        "\n",
        "Todos los entrenamientos anteriores estaban hechos sobre muestras _bootrstrap_, es decir, no estaban sobre el entrenamiento\n"
      ],
      "id": "f1f29ca7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: final-train\n",
        "final_model = LinearRegression()\n",
        "final_model.fit(X_np, y_np)\n",
        "final_r2 = r2_score(y_np, final_model.predict(X_np))"
      ],
      "id": "final-train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: optimism-correct\n",
        "corrected_r2 = final_r2 - mean_optimism\n",
        "\n",
        "print(f\"R² original: {final_r2:.4f}\")\n",
        "print(f\"Optimismo medio: {mean_optimism:.4f}\")\n",
        "print(f\"R² corregido: {corrected_r2:.4f}\")"
      ],
      "id": "optimism-correct",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\Leonardo.Hansa\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}